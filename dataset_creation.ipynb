{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e52cb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.sklearn.datasets import fetch_bank, fetch_compas, fetch_adult, fetch_german\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm as tqdm\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "604110d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X,y,_ = fetch_adult(subset='train', dropna=True)\n",
    "#X_test,y_test,_ = fetch_adult(subset='test', dropna=True)\n",
    "#X,y = fetch_german(binary_age=True, dropna=True)\n",
    "#X,y = fetch_bank(dropna=False)\n",
    "#X,y = fetch_compas()\n",
    "X,y = fetch_bank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e58b1f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>58.0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>may</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>44.0</th>\n",
       "      <td>44.0</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>may</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>33.0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>may</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>47.0</th>\n",
       "      <td>47.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>may</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>33.0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>may</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <th>51.0</th>\n",
       "      <td>51.0</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17.0</td>\n",
       "      <td>nov</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <th>71.0</th>\n",
       "      <td>71.0</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17.0</td>\n",
       "      <td>nov</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <th>72.0</th>\n",
       "      <td>72.0</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17.0</td>\n",
       "      <td>nov</td>\n",
       "      <td>5.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <th>57.0</th>\n",
       "      <td>57.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17.0</td>\n",
       "      <td>nov</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <th>37.0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17.0</td>\n",
       "      <td>nov</td>\n",
       "      <td>2.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age           job   marital  education default  balance housing  \\\n",
       "      age                                                                      \n",
       "0     58.0  58.0    management   married   tertiary      no   2143.0     yes   \n",
       "1     44.0  44.0    technician    single  secondary      no     29.0     yes   \n",
       "2     33.0  33.0  entrepreneur   married  secondary      no      2.0     yes   \n",
       "3     47.0  47.0   blue-collar   married        NaN      no   1506.0     yes   \n",
       "4     33.0  33.0           NaN    single        NaN      no      1.0      no   \n",
       "...          ...           ...       ...        ...     ...      ...     ...   \n",
       "45206 51.0  51.0    technician   married   tertiary      no    825.0      no   \n",
       "45207 71.0  71.0       retired  divorced    primary      no   1729.0      no   \n",
       "45208 72.0  72.0       retired   married  secondary      no   5715.0      no   \n",
       "45209 57.0  57.0   blue-collar   married  secondary      no    668.0      no   \n",
       "45210 37.0  37.0  entrepreneur   married  secondary      no   2971.0      no   \n",
       "\n",
       "           loan    contact   day month  campaign  pdays  previous poutcome  \n",
       "      age                                                                   \n",
       "0     58.0   no        NaN   5.0   may       1.0   -1.0       0.0      NaN  \n",
       "1     44.0   no        NaN   5.0   may       1.0   -1.0       0.0      NaN  \n",
       "2     33.0  yes        NaN   5.0   may       1.0   -1.0       0.0      NaN  \n",
       "3     47.0   no        NaN   5.0   may       1.0   -1.0       0.0      NaN  \n",
       "4     33.0   no        NaN   5.0   may       1.0   -1.0       0.0      NaN  \n",
       "...         ...        ...   ...   ...       ...    ...       ...      ...  \n",
       "45206 51.0   no   cellular  17.0   nov       3.0   -1.0       0.0      NaN  \n",
       "45207 71.0   no   cellular  17.0   nov       2.0   -1.0       0.0      NaN  \n",
       "45208 72.0   no   cellular  17.0   nov       5.0  184.0       3.0  success  \n",
       "45209 57.0   no  telephone  17.0   nov       4.0   -1.0       0.0      NaN  \n",
       "45210 37.0   no   cellular  17.0   nov       2.0  188.0      11.0    other  \n",
       "\n",
       "[45211 rows x 15 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c6299e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult Pre-Proc\n",
    "# X.drop(['education-num'], inplace=True, axis=1)\n",
    "# X_test.drop(['education-num'], inplace=True, axis=1)\n",
    "# X['income'] = y\n",
    "# X_test['income'] = y_test\n",
    "\n",
    "# Credit Pre-Proc\n",
    "# X['credit'] = y\n",
    "\n",
    "# Bank Pre-Proc\n",
    "X['deposit'] = y\n",
    "X.drop(['poutcome', 'contact'], inplace=True, axis=1)\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Compas Pre proc\n",
    "#X['category'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dab956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adult\n",
    "# stats = {}\n",
    "# stats['00'] = []\n",
    "# stats['01'] = []\n",
    "# stats['10'] = []\n",
    "# stats['11'] = []\n",
    "# for i in X.index:\n",
    "#     if X.loc[i]['sex'] == 'Female' and X.loc[i]['income'] == '<=50K':\n",
    "#         stats['01'].append(i)\n",
    "#     elif X.loc[i]['sex'] == 'Female' and X.loc[i]['income'] == '>50K':\n",
    "#         stats['00'].append(i)\n",
    "#     elif X.loc[i]['sex'] == 'Male' and X.loc[i]['income'] == '<=50K':\n",
    "#         stats['11'].append(i)\n",
    "#     elif X.loc[i]['sex'] == 'Male' and X.loc[i]['income'] == '>50K':\n",
    "#         stats['10'].append(i)\n",
    "# for i in stats:\n",
    "#     print(i, len(stats[i]))\n",
    "\n",
    "# stats_test = {}\n",
    "# stats_test['00'] = []\n",
    "# stats_test['01'] = []\n",
    "# stats_test['10'] = []\n",
    "# stats_test['11'] = []\n",
    "# for i in X_test.index:\n",
    "#     if X_test.loc[i]['sex'] == 'Female' and X_test.loc[i]['income'] == '<=50K':\n",
    "#         stats_test['01'].append(i)\n",
    "#     elif X_test.loc[i]['sex'] == 'Female' and X_test.loc[i]['income'] == '>50K':\n",
    "#         stats_test['00'].append(i)\n",
    "#     elif X_test.loc[i]['sex'] == 'Male' and X_test.loc[i]['income'] == '<=50K':\n",
    "#         stats_test['11'].append(i)\n",
    "#     elif X_test.loc[i]['sex'] == 'Male' and X_test.loc[i]['income'] == '>50K':\n",
    "#         stats_test['10'].append(i)\n",
    "# for i in stats_test:\n",
    "#     print(i, len(stats_test[i]))\n",
    "\n",
    "\n",
    "# # Credit\n",
    "# stats = {}\n",
    "# stats['00'] = []\n",
    "# stats['01'] = []\n",
    "# stats['10'] = []\n",
    "# stats['11'] = []\n",
    "# sensitives = {\n",
    "#     'sex':['female', 'male'],\n",
    "#     'foreign_worker': ['yes', 'no'],\n",
    "#     'age': ['young', 'aged']\n",
    "# }\n",
    "# attr = 'sex'\n",
    "# for i in X.index:\n",
    "#     if attr != 'age':\n",
    "#         if X.loc[i][attr] == sensitives[attr][0] and X.loc[i]['credit'] == 'good':\n",
    "#             stats['01'].append(i)\n",
    "#         elif X.loc[i][attr] == sensitives[attr][0] and X.loc[i]['credit'] == 'bad':\n",
    "#             stats['00'].append(i)\n",
    "#         elif X.loc[i][attr] == sensitives[attr][1] and X.loc[i]['credit'] == 'good':\n",
    "#             stats['11'].append(i)\n",
    "#         elif X.loc[i][attr] == sensitives[attr][1] and X.loc[i]['credit'] == 'bad':\n",
    "#             stats['10'].append(i)\n",
    "#     else:\n",
    "#         if i[2] == sensitives[attr][0] and X.loc[i]['credit'] == 'good':\n",
    "#             stats['01'].append(i)\n",
    "#         elif i[2] == sensitives[attr][0] and X.loc[i]['credit'] == 'bad':\n",
    "#             stats['00'].append(i)\n",
    "#         elif i[2] == sensitives[attr][1] and X.loc[i]['credit'] == 'good':\n",
    "#             stats['11'].append(i)\n",
    "#         elif i[2] == sensitives[attr][1] and X.loc[i]['credit'] == 'bad':\n",
    "#              stats['10'].append(i)\n",
    "\n",
    "# # Compas\n",
    "# stats = {}\n",
    "# stats['00'] = []\n",
    "# stats['01'] = []\n",
    "# stats['10'] = []\n",
    "# stats['11'] = []\n",
    "# for i in X.index:\n",
    "#     if X.loc[i]['race'] == 'African-American' and X.loc[i]['category'] == 'Recidivated':\n",
    "#         stats['01'].append(i)\n",
    "#     elif X.loc[i]['race'] == 'African-American' and X.loc[i]['category'] == 'Survived':\n",
    "#         stats['00'].append(i)\n",
    "#     elif X.loc[i]['race'] == 'Caucasian' and X.loc[i]['category'] == 'Recidivated':\n",
    "#         stats['11'].append(i)\n",
    "#     elif X.loc[i]['race'] == 'Caucasian' and X.loc[i]['category'] == 'Survived':\n",
    "#         stats['10'].append(i)\n",
    "\n",
    "# Bank\n",
    "stats = {}\n",
    "stats['00'] = []\n",
    "stats['01'] = []\n",
    "stats['10'] = []\n",
    "stats['11'] = []\n",
    "for i in X.index:\n",
    "    if X.loc[i]['age'] <= 25 and X.loc[i]['deposit'] == 'yes':\n",
    "        stats['01'].append(i)\n",
    "    elif X.loc[i]['age'] <= 25 and X.loc[i]['deposit'] == 'no':\n",
    "        stats['00'].append(i)\n",
    "    elif X.loc[i]['age'] > 25 and X.loc[i]['deposit'] == 'yes':\n",
    "        stats['11'].append(i)\n",
    "    elif X.loc[i]['age'] > 25 and X.loc[i]['deposit'] == 'no':\n",
    "        stats['10'].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab79dada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 944\n",
      "01 287\n",
      "10 37228\n",
      "11 4734\n"
     ]
    }
   ],
   "source": [
    "for i in stats:\n",
    "    print(i, len(stats[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5e2baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult\n",
    "# X.to_csv('/media/data_dump/Mohit/facct23_samplebias_data/adult/raw/original_train.csv', index=False)\n",
    "# X_test.to_csv('/media/data_dump/Mohit/facct23_samplebias_data/adult/raw/original_test.csv', index=False)\n",
    "\n",
    "# Credit\n",
    "#X.to_csv('/media/data_dump/Mohit/facct23_samplebias_data/run_1/credit/raw/original_full.csv', index=False)\n",
    "\n",
    "# Compas\n",
    "# X.to_csv('/media/data_dump/Mohit/facct23_samplebias_data/run_1/compas/raw/original_full.csv', index=False)\n",
    "\n",
    "# Bank\n",
    "X.to_csv('/media/data_dump/Mohit/facct23_samplebias_data/run_1/bank/raw/original_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5287f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIndices = []\n",
    "testIndices = []\n",
    "for i in stats:\n",
    "    random.shuffle(stats[i])\n",
    "    trainIndices.extend(stats[i][:int(len(stats[i])*0.8)])\n",
    "    testIndices.extend(stats[i][int(len(stats[i])*0.8):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "436df67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[trainIndices].to_csv('/media/data_dump/Mohit/facct23_samplebias_data/run_1/bank/raw/original_train.csv', index=False)\n",
    "X.loc[testIndices].to_csv('/media/data_dump/Mohit/facct23_samplebias_data/run_1/bank/raw/original_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a11ead8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createImbalancedDataframe(csv_path, balance=False, imbalanceFactor=1.0, dataset='adult', betaSplits=False, beta_neg_factor=None, labelFlip=None):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    xVals = list(data.index)\n",
    "    subgroups = {'00':[], '01':[], '10':[], '11':[]}\n",
    "    for i in xVals:\n",
    "        if dataset == 'adult':\n",
    "            # First index (0) -> Female Gender, Second index(0) -> <=50K, (1) -> >50K\n",
    "            if data.loc[i]['sex'] == 'Female' and data.loc[i]['income'] == '<=50K':\n",
    "                subgroups['00'].append(i)\n",
    "            elif data.loc[i]['sex'] == 'Female' and data.loc[i]['income'] == '>50K':\n",
    "                subgroups['01'].append(i)\n",
    "            elif data.loc[i]['sex'] == 'Male' and data.loc[i]['income'] == '<=50K':\n",
    "                subgroups['10'].append(i)\n",
    "            elif data.loc[i]['sex'] == 'Male' and data.loc[i]['income'] == '>50K':\n",
    "                subgroups['11'].append(i)\n",
    "        elif dataset == 'bank':\n",
    "            # <= 25 -> 0, yes -> 1\n",
    "            if data.loc[i]['age'] <= 25 and data.loc[i]['deposit'] == 'no':\n",
    "                subgroups['00'].append(i)\n",
    "            elif data.loc[i]['age'] <= 25 and data.loc[i]['deposit'] == 'yes':\n",
    "                subgroups['01'].append(i)\n",
    "            elif data.loc[i]['age'] > 25 and data.loc[i]['deposit'] == 'no':\n",
    "                subgroups['10'].append(i)\n",
    "            elif data.loc[i]['age'] > 25 and data.loc[i]['deposit'] == 'yes':\n",
    "                subgroups['11'].append(i)\n",
    "        elif dataset == 'compas':\n",
    "            if data.loc[i]['race'] == 'African-American' and data.loc[i]['category'] == 'Recidivated':\n",
    "                subgroups['01'].append(i)\n",
    "            elif data.loc[i]['race'] == 'African-American' and data.loc[i]['category'] == 'Survived':\n",
    "                subgroups['00'].append(i)\n",
    "            elif data.loc[i]['race'] == 'Caucasian' and data.loc[i]['category'] == 'Recidivated':\n",
    "                subgroups['11'].append(i)\n",
    "            elif data.loc[i]['race'] == 'Caucasian' and data.loc[i]['category'] == 'Survived':\n",
    "                subgroups['10'].append(i)\n",
    "        elif dataset == 'credit':\n",
    "            if data.loc[i]['sex'] == 'female' and data.loc[i]['credit'] == 'good':\n",
    "                subgroups['01'].append(i)\n",
    "            elif data.loc[i]['sex'] == 'female' and data.loc[i]['credit'] == 'bad':\n",
    "                subgroups['00'].append(i)\n",
    "            elif data.loc[i]['sex'] == 'male' and data.loc[i]['credit'] == 'good':\n",
    "                subgroups['11'].append(i)\n",
    "            elif data.loc[i]['sex'] == 'male' and data.loc[i]['credit'] == 'bad':\n",
    "                subgroups['10'].append(i)\n",
    "        elif dataset == 'synthetic':\n",
    "            if data.loc[i]['sensitive'] == 0 and data.loc[i]['label'] == 1:\n",
    "                subgroups['01'].append(i)\n",
    "            elif data.loc[i]['sensitive'] == 0 and data.loc[i]['label'] == 0:\n",
    "                subgroups['00'].append(i)\n",
    "            elif data.loc[i]['sensitive'] == 1 and data.loc[i]['label'] == 1:\n",
    "                subgroups['11'].append(i)\n",
    "            elif data.loc[i]['sensitive'] == 1 and data.loc[i]['label'] == 0:\n",
    "                subgroups['10'].append(i)\n",
    "    if balance == True:\n",
    "        num_points = min(len(subgroups['00']), len(subgroups['01']), len(subgroups['10']), len(subgroups['11']))\n",
    "        for i in subgroups:\n",
    "            subgroups[i] = random.sample(subgroups[i], num_points)\n",
    "    if dataset == 'adult':\n",
    "        imbalanceGroup = '01'\n",
    "        beta_neg_group = '00'\n",
    "        labelFlipIndex = '01'\n",
    "        label = 'income'\n",
    "        flipped_label = '<=50K'\n",
    "    elif dataset == 'bank':\n",
    "        imbalanceGroup = '01'\n",
    "        beta_neg_group = '00'\n",
    "        labelFlipIndex = '01'\n",
    "        label = 'deposit'\n",
    "        flipped_label = 'no'\n",
    "    elif dataset == 'compas':\n",
    "        imbalanceGroup = '11'\n",
    "        beta_neg_group = '10'\n",
    "        labelFlipIndex = '11'\n",
    "        label = 'category'\n",
    "        flipped_label = 'Survived'\n",
    "    elif dataset == 'credit':\n",
    "        imbalanceGroup = '01'\n",
    "        beta_neg_group = '00'\n",
    "        labelFlipIndex = '01'\n",
    "        label = 'credit'\n",
    "        flipped_label = 'bad'\n",
    "    elif dataset == 'synthetic':\n",
    "        imbalanceGroup = '01'\n",
    "        beta_neg_group = '00'\n",
    "        labelFlipIndex = '01'\n",
    "        label = 'label'\n",
    "        flipped_label = 0\n",
    "    if labelFlip is not None:\n",
    "        noisyIndices = random.sample(subgroups[labelFlipIndex], int(len(subgroups[labelFlipIndex])*labelFlip))\n",
    "        for i in noisyIndices:\n",
    "            data.at[i,label]  = flipped_label\n",
    "        return data\n",
    "    else:\n",
    "        if betaSplits == True:\n",
    "            subgroups[imbalanceGroup] = random.sample(subgroups[imbalanceGroup], int(len(subgroups[imbalanceGroup])*imbalanceFactor))\n",
    "            subgroups[beta_neg_group] = random.sample(subgroups[beta_neg_group], int(len(subgroups[beta_neg_group])*beta_neg_factor))\n",
    "        newDataset = subgroups['00'] + subgroups['01'] + subgroups['10'] + subgroups['11']\n",
    "        return data.loc[newDataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c7cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946a1c173081458385b39e19ff03654b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We retain the train-test splits, but recreate the beta_pos-beta_neg splits for reproducibility\n",
    "dataset = 'adult'\n",
    "run = 2\n",
    "for beta_pos in tqdm(np.arange(1,11)):\n",
    "    beta_pos = beta_pos/10\n",
    "    for beta_neg in np.arange(1,11):\n",
    "        beta_neg = beta_neg/10\n",
    "        # Create train set\n",
    "        temp = createImbalancedDataframe(f'/media/data_dump/Mohit/facct23_samplebias_data/run_1/{dataset}/raw/original_train.csv', imbalanceFactor=beta_pos, dataset=dataset, betaSplits=True, beta_neg_factor=beta_neg)\n",
    "        temp.to_csv(f'/media/data_dump/Mohit/facct23_samplebias_data/run_{run}/{dataset}/raw/betaDatasets/imbalance_{beta_pos}_{beta_neg}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'adult'\n",
    "run = 2\n",
    "for nu in tqdm(np.arange(0,10)):\n",
    "    nu = nu/10\n",
    "    temp = createImbalancedDataframe(f'/media/data_dump/Mohit/facct23_samplebias_data/run_1/{dataset}/raw/original_train.csv', balance=False, dataset=dataset, labelFlip=nu)\n",
    "    temp.to_csv(f'/media/data_dump/Mohit/facct23_samplebias_data/run_{run}/{dataset}/raw/labelBiasDatasets/imbalance_{nu}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-elizabeth",
   "metadata": {},
   "source": [
    "### Synthetic Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "laden-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "forward-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(num_examples=20000, dim=100, var=1, means=None):\n",
    "    #num_a_1 = int(0.7*num_examples) # 14000\n",
    "    #num_a_0 = num_examples - num_a_1 # 6000\n",
    "    num_a_1 = 0\n",
    "    num_a_0 = 0\n",
    "    for i in range(num_examples):\n",
    "        if np.random.uniform(0,1) < 0.7:\n",
    "            num_a_1 += 1\n",
    "        else:\n",
    "            num_a_0 += 1\n",
    "    # subgroup populations\n",
    "    #num_y_1_a_1 = int(0.7*num_a_1) # 9800\n",
    "    #num_y_0_a_1 = num_a_1 - num_y_1_a_1 # 4200\n",
    "    #num_y_1_a_0 = int(0.4*num_a_0) # 2400\n",
    "    #num_y_0_a_0 = num_a_0 - num_y_1_a_0 # 3600\n",
    "    num_y_1_a_1 = 0\n",
    "    num_y_0_a_1 = 0\n",
    "    for i in range(num_a_1):\n",
    "        if np.random.uniform(0,1) < 0.7:\n",
    "            num_y_1_a_1 += 1\n",
    "        else:\n",
    "            num_y_0_a_1 += 1\n",
    "    num_y_1_a_0 = 0\n",
    "    num_y_0_a_0 = 0\n",
    "    for i in range(num_a_0):\n",
    "        if np.random.uniform(0,1) < 0.4:\n",
    "            num_y_1_a_0 += 1\n",
    "        else:\n",
    "            num_y_0_a_0 += 1\n",
    "    #print(num_y_1_a_1, num_y_0_a_1, num_y_1_a_0, num_y_0_a_0)\n",
    "    # groupwise pdfs mu_y_a\n",
    "    if means == None:\n",
    "        mu_0_0 = [np.random.uniform(0,1) for i in range(dim)]\n",
    "        mu_0_1 = [np.random.uniform(0,1) for i in range(dim)]\n",
    "        mu_1_0 = [np.random.uniform(0,1) for i in range(dim)]\n",
    "        mu_1_1 = [np.random.uniform(0,1) for i in range(dim)]\n",
    "    else:\n",
    "        mu_0_0 = means[0]\n",
    "        mu_0_1 = means[1]\n",
    "        mu_1_0 = means[2]\n",
    "        mu_1_1 = means[3]\n",
    "    covar = var*np.eye(dim)\n",
    "    # Samples\n",
    "    samples_0_0 = np.random.multivariate_normal(mu_0_0, covar, num_y_0_a_0)\n",
    "    samples_0_1 = np.random.multivariate_normal(mu_0_1, covar, num_y_0_a_1)\n",
    "    samples_1_0 = np.random.multivariate_normal(mu_1_0, covar, num_y_1_a_0)\n",
    "    samples_1_1 = np.random.multivariate_normal(mu_1_1, covar, num_y_1_a_1)\n",
    "    sensitive = np.asarray([0]*len(samples_0_0) + [1]*len(samples_0_1) + [0]*len(samples_1_0) + [1]*len(samples_1_1))\n",
    "    label = np.asarray([0]*len(samples_0_0) + [0]*len(samples_0_1) + [1]*len(samples_1_0) + [1]*len(samples_1_1))\n",
    "    return [mu_0_0, mu_0_1, mu_1_0, mu_1_1], np.vstack((samples_0_0, samples_0_1, samples_1_0, samples_1_1)), sensitive, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "humanitarian-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, x, z, y = generate_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "mounted-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(len(x)):\n",
    "    row = {}\n",
    "    for j in range(len(x[i])):\n",
    "        row[f'fea{j}'] = x[i][j]\n",
    "    row['sensitive'] = z[i]\n",
    "    row['label'] = y[i]\n",
    "    rows.append(row)\n",
    "train_dataset = pd.DataFrame.from_dict(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "meaning-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x, z, y = generate_examples(means=means, num_examples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "foreign-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(len(x)):\n",
    "    row = {}\n",
    "    for j in range(len(x[i])):\n",
    "        row[f'fea{j}'] = x[i][j]\n",
    "    row['sensitive'] = z[i]\n",
    "    row['label'] = y[i]\n",
    "    rows.append(row)\n",
    "test_dataset = pd.DataFrame.from_dict(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "indirect-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv('/media/data_dump/Mohit/facct23_samplebias_data/run_1/synthetic/raw/original_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "occupied-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.to_csv('/media/data_dump/Mohit/facct23_samplebias_data/run_1/synthetic/raw/original_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "subtle-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/data_dump/Mohit/facct23_samplebias_data/run_1/synthetic/means.pkl', 'wb') as f:\n",
    "    pickle.dump(means, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-championship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
