{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df04a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import preprocessDataset\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c00df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'credit'\n",
    "train_dataset, test_dataset_original = preprocessDataset(f'/media/data_dump/Mohit/facct23_samplebias_data/run_1/{dataset}/raw/betaDatasets/imbalance_1.0_1.0', f'/media/data_dump/Mohit/facct23_samplebias_data/run_1/{dataset}/raw/original_test.csv', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddd7daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import math\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f40ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = train_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3298a798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(798, 59)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8cafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier, NeuralNet\n",
    "import skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af32d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, data_shape, nonlin=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        # -1 for sensitive attribute removal (group-blind training)\n",
    "        num_units = math.ceil((2*data_shape[0])/(data_shape[1] - 1))\n",
    "        self.dense0 = nn.Linear(data_shape[1] - 1, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, data, sample_weight=1, **kwargs):\n",
    "        X = data\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.softmax(self.output(X))\n",
    "        return X\n",
    "\n",
    "class MyNet(NeuralNet):\n",
    "    def __init__(self, *args, criterion__reduce=False, **kwargs):\n",
    "        # make sure to set reduce=False in your criterion, since we need the loss\n",
    "        # for each sample so that it can be weighted\n",
    "        super().__init__(*args, criterion__reduce=criterion__reduce, **kwargs)\n",
    "\n",
    "    def get_loss(self, y_pred, y_true, X, *args, **kwargs):\n",
    "        # override get_loss to use the sample_weight from X\n",
    "        loss_unreduced = super().get_loss(y_pred, y_true, X, *args, **kwargs)\n",
    "        sample_weight = skorch.utils.to_tensor(X['sample_weight'], device=self.device)\n",
    "        loss_reduced = (sample_weight * loss_unreduced).mean()\n",
    "        return loss_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edfd42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyNet(\n",
    "    MyModule(data_shape),\n",
    "    criterion=nn.NLLLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=None,\n",
    "    max_epochs=100,\n",
    "    lr=0.01,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "armed-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_2 = NeuralNetClassifier(\n",
    "    MyModule(data_shape),\n",
    "    criterion=nn.NLLLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=None,\n",
    "    max_epochs=100,\n",
    "    lr=0.01,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ba5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_dataset.features[:,:-1]\n",
    "y = train_dataset.labels.ravel().astype(int)\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b055fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = {'data': X,\n",
    "#     'sample_weight': np.ones_like(y).astype(np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79ca49f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6120\u001b[0m  0.0289\n",
      "      2        \u001b[36m0.5311\u001b[0m  0.0233\n",
      "      3        \u001b[36m0.4846\u001b[0m  0.0253\n",
      "      4        \u001b[36m0.4595\u001b[0m  0.0234\n",
      "      5        \u001b[36m0.4497\u001b[0m  0.0235\n",
      "      6        \u001b[36m0.4362\u001b[0m  0.0327\n",
      "      7        \u001b[36m0.4206\u001b[0m  0.0324\n",
      "      8        \u001b[36m0.4120\u001b[0m  0.0260\n",
      "      9        \u001b[36m0.3993\u001b[0m  0.0238\n",
      "     10        \u001b[36m0.3853\u001b[0m  0.0240\n",
      "     11        \u001b[36m0.3704\u001b[0m  0.0237\n",
      "     12        \u001b[36m0.3569\u001b[0m  0.0234\n",
      "     13        \u001b[36m0.3436\u001b[0m  0.0240\n",
      "     14        \u001b[36m0.3311\u001b[0m  0.0226\n",
      "     15        \u001b[36m0.3127\u001b[0m  0.0242\n",
      "     16        \u001b[36m0.2981\u001b[0m  0.0230\n",
      "     17        \u001b[36m0.2874\u001b[0m  0.0236\n",
      "     18        \u001b[36m0.2780\u001b[0m  0.0227\n",
      "     19        \u001b[36m0.2758\u001b[0m  0.0234\n",
      "     20        \u001b[36m0.2433\u001b[0m  0.0241\n",
      "     21        \u001b[36m0.2330\u001b[0m  0.0238\n",
      "     22        \u001b[36m0.2241\u001b[0m  0.0233\n",
      "     23        \u001b[36m0.2140\u001b[0m  0.0241\n",
      "     24        \u001b[36m0.1993\u001b[0m  0.0231\n",
      "     25        \u001b[36m0.1932\u001b[0m  0.0235\n",
      "     26        \u001b[36m0.1826\u001b[0m  0.0233\n",
      "     27        \u001b[36m0.1752\u001b[0m  0.0240\n",
      "     28        \u001b[36m0.1691\u001b[0m  0.0233\n",
      "     29        \u001b[36m0.1602\u001b[0m  0.0235\n",
      "     30        \u001b[36m0.1518\u001b[0m  0.0233\n",
      "     31        \u001b[36m0.1426\u001b[0m  0.0240\n",
      "     32        \u001b[36m0.1350\u001b[0m  0.0235\n",
      "     33        \u001b[36m0.1251\u001b[0m  0.0237\n",
      "     34        \u001b[36m0.1249\u001b[0m  0.0236\n",
      "     35        \u001b[36m0.1136\u001b[0m  0.0236\n",
      "     36        \u001b[36m0.1134\u001b[0m  0.0232\n",
      "     37        \u001b[36m0.1114\u001b[0m  0.0231\n",
      "     38        \u001b[36m0.0974\u001b[0m  0.0234\n",
      "     39        \u001b[36m0.0899\u001b[0m  0.0234\n",
      "     40        \u001b[36m0.0869\u001b[0m  0.0233\n",
      "     41        \u001b[36m0.0785\u001b[0m  0.0234\n",
      "     42        \u001b[36m0.0773\u001b[0m  0.0231\n",
      "     43        \u001b[36m0.0741\u001b[0m  0.0239\n",
      "     44        \u001b[36m0.0719\u001b[0m  0.0234\n",
      "     45        \u001b[36m0.0677\u001b[0m  0.0244\n",
      "     46        \u001b[36m0.0660\u001b[0m  0.0235\n",
      "     47        0.0681  0.0234\n",
      "     48        0.0706  0.0230\n",
      "     49        \u001b[36m0.0579\u001b[0m  0.0237\n",
      "     50        \u001b[36m0.0521\u001b[0m  0.0233\n",
      "     51        \u001b[36m0.0482\u001b[0m  0.0240\n",
      "     52        \u001b[36m0.0456\u001b[0m  0.0236\n",
      "     53        \u001b[36m0.0440\u001b[0m  0.0240\n",
      "     54        \u001b[36m0.0418\u001b[0m  0.0238\n",
      "     55        0.0475  0.0233\n",
      "     56        0.0441  0.0233\n",
      "     57        \u001b[36m0.0406\u001b[0m  0.0240\n",
      "     58        \u001b[36m0.0379\u001b[0m  0.0236\n",
      "     59        \u001b[36m0.0361\u001b[0m  0.0232\n",
      "     60        \u001b[36m0.0332\u001b[0m  0.0236\n",
      "     61        0.0348  0.0231\n",
      "     62        \u001b[36m0.0322\u001b[0m  0.0237\n",
      "     63        \u001b[36m0.0276\u001b[0m  0.0234\n",
      "     64        0.0277  0.0233\n",
      "     65        0.0284  0.0235\n",
      "     66        0.0311  0.0233\n",
      "     67        0.0288  0.0235\n",
      "     68        \u001b[36m0.0258\u001b[0m  0.0234\n",
      "     69        \u001b[36m0.0226\u001b[0m  0.0241\n",
      "     70        0.0237  0.0230\n",
      "     71        \u001b[36m0.0218\u001b[0m  0.0230\n",
      "     72        \u001b[36m0.0210\u001b[0m  0.0236\n",
      "     73        \u001b[36m0.0184\u001b[0m  0.0233\n",
      "     74        \u001b[36m0.0183\u001b[0m  0.0241\n",
      "     75        \u001b[36m0.0183\u001b[0m  0.0236\n",
      "     76        0.0187  0.0233\n",
      "     77        \u001b[36m0.0171\u001b[0m  0.0234\n",
      "     78        0.0197  0.0235\n",
      "     79        0.0181  0.0235\n",
      "     80        \u001b[36m0.0171\u001b[0m  0.0236\n",
      "     81        0.0201  0.0233\n",
      "     82        0.0176  0.0240\n",
      "     83        \u001b[36m0.0152\u001b[0m  0.0234\n",
      "     84        \u001b[36m0.0144\u001b[0m  0.0240\n",
      "     85        \u001b[36m0.0135\u001b[0m  0.0234\n",
      "     86        0.0154  0.0235\n",
      "     87        0.0148  0.0232\n",
      "     88        \u001b[36m0.0125\u001b[0m  0.0235\n",
      "     89        \u001b[36m0.0125\u001b[0m  0.0236\n",
      "     90        \u001b[36m0.0111\u001b[0m  0.0235\n",
      "     91        0.0111  0.0238\n",
      "     92        \u001b[36m0.0107\u001b[0m  0.0233\n",
      "     93        0.0108  0.0237\n",
      "     94        \u001b[36m0.0100\u001b[0m  0.0229\n",
      "     95        0.0109  0.0246\n",
      "     96        0.0113  0.0233\n",
      "     97        0.0103  0.0235\n",
      "     98        \u001b[36m0.0098\u001b[0m  0.0234\n",
      "     99        0.0106  0.0237\n",
      "    100        \u001b[36m0.0087\u001b[0m  0.0236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (dense0): Linear(in_features=58, out_features=28, bias=True)\n",
       "    (nonlin): ReLU()\n",
       "    (output): Linear(in_features=28, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exciting-express",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_2.predict(X)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brilliant-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset_original\n",
    "X_test = test_dataset.features[:,:-1]\n",
    "y_test = test_dataset.labels.ravel().astype(int)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "X_test = {'data': X_test,\n",
    "    'sample_weight': np.ones_like(y_test).astype(np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gorgeous-survival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848140770252324"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, np.argmax(net.predict(X_test), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "usual-entity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541210795040116"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, np.argmax(net.predict(X), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "perfect-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "loose-senior",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    }
   ],
   "source": [
    "cls = MLPClassifier(hidden_layer_sizes=(math.ceil((2*data_shape[0])/(data_shape[1] - 1)),)).fit(X['data'],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "yellow-colleague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9246071215436642"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, cls.predict(X['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "labeled-actress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8310756972111554"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, cls.predict(X_test['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-japan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from folktables import ACSIncome, ACSDataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc9b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_source = ACSDataSource(survey_year='2018', horizon='5-Year', survey='person', #root_dir='/media/data_dump/Mohit/facct23_samplebias_data/large_adult_source/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc055da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acs_data = data_source.get_data(download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1be4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
